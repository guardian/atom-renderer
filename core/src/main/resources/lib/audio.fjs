//@flow

import { Actions, MediaEvents } from 'ophan';
import type { Channel } from 'channels';
import { fromEvent } from 'events-getter';

type AudioF = { player: HTMLElement
              , playPauseButton: HTMLElement
              , timePlayed: HTMLElement
              , timeDuration: HTMLElement
              , scrubber: HTMLElement
              };
type Audio = AudioF & Atom;

function setPlayingState(dom: DomService, playPauseButton: HTMLElement) {
  dom.write(() => {
    playPauseButton.classList.add('is-playing');
  });
}

function setPausedState(dom: DomService, playPauseButton: HTMLElement) {
  dom.write(() => {
    playPauseButton.classList.remove('is-playing');
  });
}

function formatTime(t: number): string {
  const format = (t: number) => t.toFixed(0).padStart(2, '0');
  const second = Math.floor(t % 60);
  const minute = Math.floor((t % 3600) / 60);
  const hour = Math.floor(t / 3600);
  return `${format(hour)}:${format(minute)}:${format(second)}`;
}

function setupTime(dom: DomService, audio: Audio) {
  dom.write(() => {
    audio.scrubber.value = 0;
    audio.timePlayed.innerText = formatTime(0);
    audio.timeDuration.innerText = formatTime(Number(audio.player.getAttribute('data-duration')) || 0);
  });
}

function recordOphanAudioEvent(id: string, eventName: string) {
  ophan.record({
    audio: {
      id,
      eventType: `audio:content:${eventName}`,
    },
  });
}

function updateTime(dom: DomService, audio: Audio) {
  const now = Date.now();
  const last = audio.player.getAttribute('last-tick');

  // throttle to 1 update per second
  if (now - (Number(last) || 0) < 1000) return;

  const played = Math.floor(audio.player.currentTime);
  const duration = Number(audio.player.getAttribute('data-duration')) || 1; // avoid divide by zero if not present
  const percentPlayed = Math.floor(played / duration * 100);
  const gradientDescription = `linear-gradient(to right, #C70000 ${percentPlayed}%, #afafaf ${percentPlayed}%)`;

  dom.write(() => {
    audio.scrubber.value = percentPlayed;
    audio.player.setAttribute('last-tick', now.toString());
    audio.scrubber.style.background = gradientDescription;
    audio.timePlayed.innerText = formatTime(played);
  });
}

export default (componentType: ComponentType) => ({ ophan, dom, viewport }: Services): AtomBuilder<AudioF> => (root: HTMLElement): Coeval<Audio> => {
  let playPauseC: Channel<Action>;
  let scrubC: Channel<Action>;
  let playerTimeUpdateC: Channel<Action>;
  let observer: (x: number) => void;
  const audioContainerSelector = '.atom--audio';
  const audioPlayerSelector = '.atom--audio__player-element';
  const playPauseButtonSelector = '.atom--audio__button-playaudio';
  const progressBarSelector = '.atom--audio__progress-bar';
  const progressSlider = '.atom--audio__progress-bar > input';
  const timePlayedSelector = '.atom--audio__time-played > span';
  const timeDurationSelector = '.atom--audio__time-duration > span';

  const start = (a: Audio): Promise<void> => {
    playPauseC = fromEvent('click', a.playPauseButton)
      .map((e: Event) => ((e.target: any).closest(playPauseButtonSelector): ?HTMLButtonElement))
      .filter((e: ?HTMLButtonElement) => !!e);
    playPauseC.tap(onPlayPause(a));

    const firstPlayC = fromEvent('click', a.playPauseButton)
      .map((e: Event) => ((e.target: any).closest(playPauseButtonSelector): ?HTMLButtonElement))
      .filter((e: ?HTMLButtonElement) => !!e)
      .takeN(1);
    playPauseC.tap(onFirstPlay(a));

    playerTimeUpdateC = fromEvent('timeupdate', a.player)
      .map((e: Event) => ((e.target: any).closest(audioPlayerSelector): ?HTMLElement))
      .filter((e: ?HTMLElement) => !!e);
    playerTimeUpdateC.tap(onTick(a));

    observer = onVisible(a);
    viewport.observe(root, 1, observer);

    recordOphanAudioEvent(a.player.getAttribute('data-media-id') || '', MediaEvents.READY);

    return Promise.resolve();
  };
  
  const stop = () => {
    playPauseC.close();
    playerTimeUpdateC.close();
    viewport.unobserve(root, 1, observer);
  };

  const onPlayPause = (p: Audio) => (b: HTMLButtonElement): void => {
    if (p.player.paused) {
      setPlayingState(dom, p.playPauseButton);
      p.player.play();
      p.player.ontimeupdate = updateTime(dom, p);
    } else {
      setPausedState(dom, p.playPauseButton);
      p.player.pause();
    }
  };

  const onFirstPlay = (p: Audio) => (b: HTMLButtonElement): void => {
    recordOphanAudioEvent(p.player.getAttribute('data-media-id') || '', MediaEvents.PLAY);
  }

  const onTick = (p: Audio) => (a: Action): void => {
    //TODO: send progress events to Ophan - needs thought re deduplication because it's based on percentage played
    updateTime(dom, p);
  };

  const onVisible = (p: Audio) => (ratio: number): void => {
    if (ratio >= 1) {
      setupTime(dom, p);
      viewport.unobserve(root, 1, observer);
    }
  };

  const runTry = (): Try<Audio> => {
    const playPauseButton = (root.querySelector(playPauseButtonSelector): ?HTMLElement);
    const scrubber = (root.querySelector(progressSlider): ?HTMLElement);
    const audio = (root.querySelector(audioContainerSelector): ?HTMLElement);
    const player = (root.querySelector(audioPlayerSelector): ?HTMLElement);
    const timePlayed = (root.querySelector(timePlayedSelector): ?HTMLElement);
    const timeDuration = (root.querySelector(timeDurationSelector): ?HTMLElement);

    return audio && player && playPauseButton && timePlayed && timeDuration && scrubber
      ? Object.freeze({
        atomId: (root.dataset.atomId: string),
        player: player,
        playPauseButton,
        timePlayed,
        timeDuration,
        scrubber,
        stop,
        start(): Promise<void> {
          return start(this);
        }
      })
      : 'Some elements were missing when initialising atom';
  };

  return Object.freeze({ runTry });
}