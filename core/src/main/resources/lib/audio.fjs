//@flow

import { Actions, MediaEvents } from 'ophan';

type AudioF = { player: HTMLElement
              , playPauseButton: HTMLElement
              , timePlayed: HTMLElement
              , timeDuration: HTMLElement
              , scrubber: HTMLElement
              };
type Audio = AudioF & Atom;

function formatTime(t: number): string {
  const format = (t: number) => t.toFixed(0).padStart(2, '0');
  const second = Math.floor(t % 60);
  const minute = Math.floor((t % 3600) / 60);
  const hour = Math.floor(t / 3600);
  return `${format(hour)}:${format(minute)}:${format(second)}`;
}

export default (componentType: ComponentType) => ({ ophan, dom, viewport }: Services): AtomBuilder<AudioF> => (root: HTMLElement): Coeval<Audio> => {
  let audio: Audio;
  let duration: number;
  const audioContainerSelector = '.atom--audio';
  const audioPlayerSelector = '.atom--audio__player-element';
  const playPauseButtonSelector = '.atom--audio__button-playaudio';
  const progressSliderSelector = '.atom--audio__progress-bar > input';
  const timePlayedSelector = '.atom--audio__time-played > span';
  const timeDurationSelector = '.atom--audio__time-duration > span';

  const start = (a: Audio): Promise<void> => {
    /*
      Safari 11+ doesn't recognise our handling of a click event intercepted over a Channel and therefore
      refuses to start playback in response, so we'll use the default addEventListener technique instead
    */
    audio = a;
    audio.playPauseButton.addEventListener('click', onPlayPause);
    audio.scrubber.addEventListener('input', onTimeSeek);
    audio.scrubber.addEventListener('change', onTimeSeek);
    audio.player.addEventListener('timeupdate', updateTime);
    audio.player.addEventListener('ended', onPlaybackFinished);
    audio.player.addEventListener('durationchange', onDurationChange);
    viewport.observe(root, 1, onVisible);
    
    recordOphanAudioEvent(a.player.getAttribute('data-media-id') || '', MediaEvents.READY);
     
    duration = Number(audio.player.getAttribute('data-duration')) || 1; // avoid divide by zero if not present

    return Promise.resolve();
  };
  
  const stop = () => {
    viewport.unobserve(root, 1, onVisible);
    audio.playPauseButton.removeEventListener('click', onPlayPause);
    audio.scrubber.removeEventListener('input', onTimeSeek);
    audio.scrubber.removeEventListener('change', onTimeSeek);
    audio.player.removeEventListener('timeupdate', updateTime);
    audio.player.removeEventListener('ended', onPlaybackFinished);
    audio = null;
  };

  const recordOphanAudioEvent = (id: string, eventName: string) => {
    ophan.record({
      audio: {
        id,
        eventType: `audio:content:${eventName}`,
      },
    });
  };

  const setPlayingState = (playPauseButton: HTMLElement) => {
    dom.write(() => {
      playPauseButton.classList.add('is-playing');
    });
  };

  const setPausedState = (playPauseButton: HTMLElement) => {
    dom.write(() => {
      playPauseButton.classList.remove('is-playing');
    });
  };

  const showProgress = (audio: Audio, percentPlayed: Number, now: Number, played: string) => {
    const gradientDescription = `linear-gradient(to right, #C70000 ${percentPlayed}%, #afafaf ${percentPlayed}%)`;

    dom.write(() => {
      audio.scrubber.value = percentPlayed;
      audio.player.setAttribute('data-last-tick', now.toString());
      audio.scrubber.style.background = gradientDescription;
      audio.timePlayed.innerText = formatTime(played);
    });
  };

  const onDurationChange = () => {
    audio.timeDuration.innerText = formatTime(audio.player.duration);
    audio.player.removeEventListener('durationchange', onDurationChange);
    duration = audio.player.duration;
  };

  const updateTime = (): void => {
    const now = Date.now();
    const last = audio.player.getAttribute('data-last-tick');

    // throttle to 1 update per second
    if (now - (Number(last) || 0) < 1000) return;

    const played = Math.floor(audio.player.currentTime);
    const percentPlayed = Math.floor(played / duration * 100);
    const milestones = audio.player.getAttribute('data-milestones') || '';

    if (percentPlayed >= 25 && milestones.indexOf(MediaEvents.PERCENT25) < 0){
      audio.player.setAttribute('data-milestones', milestones.concat(`${MediaEvents.PERCENT25},`));
      recordOphanAudioEvent(audio.player.getAttribute('data-media-id'), MediaEvents.PERCENT25);
    }
    if (percentPlayed >= 50 && milestones.indexOf(MediaEvents.PERCENT50) < 0){
      audio.player.setAttribute('data-milestones', milestones.concat(`${MediaEvents.PERCENT50},`));
      recordOphanAudioEvent(audio.player.getAttribute('data-media-id'), MediaEvents.PERCENT50);
    }
    if (percentPlayed >= 75 && milestones.indexOf(MediaEvents.PERCENT75) < 0){
      audio.player.setAttribute('data-milestones', milestones.concat(`${MediaEvents.PERCENT75},`));
      recordOphanAudioEvent(audio.player.getAttribute('data-media-id'), MediaEvents.PERCENT75);
    }

    showProgress(audio, percentPlayed, now, played);

  };

  const onPlayPause = (): void => {
    if (audio.player.paused) {
      const milestones = audio.player.getAttribute('data-milestones') || '';
      if (milestones.indexOf(Actions.PLAY) < 0 ) {
        audio.player.setAttribute('data-milestones', milestones.concat(`${MediaEvents.PLAY},`));
        recordOphanAudioEvent(audio.player.getAttribute('data-media-id'), MediaEvents.PLAY);
      }
      setPlayingState(audio.playPauseButton);
      audio.player.play();
    } else {
      setPausedState(audio.playPauseButton);
      audio.player.pause();
    }
  };

  const onVisible = (ratio: number): void => {
    if (ratio >= 1) {
      recordOphanAudioEvent(audio.player.getAttribute('data-media-id'), Actions.VIEW);
      viewport.unobserve(root, 1, onVisible);
    }
  };

  const onTimeSeek = (): void => {
    const percentSought = Number(audio.scrubber.value) || 0;
    const played = Math.floor(duration * percentSought / 100);
    const now = Date.now();
    audio.player.currentTime = played;
    showProgress(audio, percentSought, now, played);
  };

  const onPlaybackFinished = (): void => {
    const percentReached = 100;
    const now = Date.now();
    const milestones = audio.player.getAttribute('data-milestones') || '';
    if (milestones.indexOf(Actions.THE_END) < 0 ) {
      recordOphanAudioEvent(audio.player.getAttribute('data-media-id'), MediaEvents.THE_END);
      audio.player.setAttribute('data-milestones', milestones.concat(`${MediaEvents.THE_END},`));
    }
    audio.player.currentTime = duration;
    setPausedState(audio.playPauseButton);
    showProgress(audio, percentReached, now, duration);
  };

  const runTry = (): Try<Audio> => {
    const playPauseButton = (root.querySelector(playPauseButtonSelector): ?HTMLElement);
    const scrubber = (root.querySelector(progressSliderSelector): ?HTMLElement);
    const audio = (root.querySelector(audioContainerSelector): ?HTMLElement);
    const player = (root.querySelector(audioPlayerSelector): ?HTMLElement);
    const timePlayed = (root.querySelector(timePlayedSelector): ?HTMLElement);
    const timeDuration = (root.querySelector(timeDurationSelector): ?HTMLElement);

    return audio && player && playPauseButton && timePlayed && timeDuration && scrubber
      ? Object.freeze({
        atomId: (root.dataset.atomId: string),
        player: player,
        playPauseButton,
        timePlayed,
        timeDuration,
        scrubber,
        stop,
        start(): Promise<void> {
          return start(this);
        }
      })
      : 'Some elements were missing when initialising atom';
  };

  return Object.freeze({ runTry });
}